{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainTT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsmingam/TrabajoDeTitulacion/blob/main/Script%20principal%20del%20%20trabajo%20de%20titulacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE7ER9_hfLBm"
      },
      "source": [
        "**Importar las librerias y/o paquetes necesarios para el proceso de ML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-fPXsnE2fjF"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import collections\n",
        "from sklearn import linear_model\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from difflib import SequenceMatcher as SM\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHIDqbONB54"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XLOCzEsNCXw"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT8UZCyAfdk8"
      },
      "source": [
        "**Autentificación para poder acceder a los archivos almacenados en Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujEKEyIFBsQg"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NHzHvDWf1A0"
      },
      "source": [
        "**Abrir el csv y se almacenarlo en un dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1azO9E2tHnC",
        "outputId": "9b83ed2f-161b-4a71-ab97-49f3bfff1e16"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "def _loadCsv():\n",
        "  global df\n",
        "  id = '17_JBT4y9XoJYOAqui_tKxvICsbMOckMX'\n",
        "  downloaded = drive.CreateFile({'id':id}) \n",
        "  downloaded.GetContentFile('dataset.csv')\n",
        "  df = pd.read_csv('dataset.csv', converters={'cedula': lambda x: str(x), 'asignatura': lambda x: str(x.strip())})\n",
        "_loadCsv()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36362, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlNoAX8ZuFtL"
      },
      "source": [
        "**Eliminamos registros que tengan valores nulos en la variables de interes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x9IFwojQNtG",
        "outputId": "5025428d-ec61-411c-89c3-b213908e000b"
      },
      "source": [
        "_loadCsv()\n",
        "dataset = df.copy(deep=True)\n",
        "\n",
        "dataset.dropna(subset=['asignatura'], inplace=True)\n",
        "dataset.dropna(subset=['estado_asignatura'], inplace=True)\n",
        "dataset.dropna(subset=['estado_matricula'], inplace=True)\n",
        "dataset.dropna(subset=['cedula'], inplace=True)\n",
        "\n",
        "dataset.drop(dataset[dataset['estado_matricula']==\"Matriculada\"].index, inplace=True)\n",
        "dataset.drop(dataset[dataset['malla_curricular']==\"Exámen complexivo\"].index, inplace=True)\n",
        "dataset.drop(dataset[dataset['malla_curricular']==\"UTE\"].index, inplace=True)\n",
        "dataset.drop(dataset[dataset['estado_matricula']==\"Reubicada\"].index, inplace=True)\n",
        "\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30187, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47UOb8aedelj"
      },
      "source": [
        "**Eliminar las columnas que no se vinculan con los objetivos del negocio, eliminamos los diacríticos y convertimos a mayúsculas los registros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5zvIUtPnKox"
      },
      "source": [
        "columns=['facultad', 'nacionalidad', 'modalidad','pais_nacimiento', 'provincia_nacimiento', 'tipo_colegio', 'ciudad_nacimiento', 'direccion_nacimiento', 'pais_actual', 'provincia_actual', 'canton_actual', \n",
        "         'parroquia_actual', 'ciudad_actual','direccion_actual', 'colegio', 'pais_colegio', 'provincia_colegio', 'canton_colegio', 'numero_matricula', 'jornada','obligatoria', 'arrastrable',\n",
        "         'asistencia_obligatoria', 'nota_ingresada', 'nota_ponderada', 'nombres', 'apellidos', 'promedio_matricula', 'porcentaje_asistencias', 'homologada', 'observacion_homologacion'\n",
        "        ]\n",
        "dataset = dataset.drop(columns, axis=1)\n",
        "cols = dataset.select_dtypes(include=[np.object]).columns \n",
        "dataset[cols] = dataset[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.upper())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAN1yZlAgc1s"
      },
      "source": [
        "**Creamos los métodos que se utilizarán mas adelante**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehrqHkj4gWyN"
      },
      "source": [
        "def validarCedulaEcuador(cedula):\n",
        "  d_verificador = int(cedula[9]);\n",
        "  sum = 0\n",
        "  for i in range(len(cedula)-1):\n",
        "    char = int(cedula[i])\n",
        "    if(i % 2 == 0):\n",
        "      char = char * 2\n",
        "      if(char > 9):\n",
        "        char = char - 9\n",
        "    sum +=char\n",
        "  result = 10 - (sum % 10)\n",
        "  if(result == 10):\n",
        "    result = 0\n",
        "    d_verificador = 0\n",
        "  return result == d_verificador\n",
        "\n",
        "def encontrarCedulaSemejante(cedulas, ced):\n",
        "  lista = list()\n",
        "  for cedula in cedulas:\n",
        "    cedula = str(cedula)\n",
        "    if((SM(None, cedula, ced).ratio() >= 0.9) and (SM(None, cedula, ced).ratio() != 1.0)):\n",
        "      if((cedula in lista) == False):\n",
        "        lista.append(str(cedula))\n",
        "  return  lista\n",
        "\n",
        "def encontrarAsignaturaSemejante(asignaturas, asig):\n",
        "  lista = list()\n",
        "  for asignatura in asignaturas:\n",
        "    asignatura = str(asignatura)\n",
        "    if((SM(None, asignatura, asig).ratio() >= 0.85) and (SM(None, asignatura, asig).ratio() != 1.0)):\n",
        "      if((asignatura in lista) == False):\n",
        "        lista.append(asignatura)\n",
        "  return  lista\n",
        "\n",
        "def cal_edad(f):\n",
        "  today = date.today()\n",
        "  fnac = datetime.strptime(f, '%Y-%m-%d').date()\n",
        "  return today.year - fnac.year - ((today.month, today.day) < (fnac.month, fnac.day))\n",
        "\n",
        "def format(cad):\n",
        "  cad = cad.strip() \n",
        "  return cad.replace(\" \", \"_\") \n",
        "\n",
        "def isColumn(lista, col):\n",
        "  for x in lista:\n",
        "    if x == col:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQgt8HSc9TYl"
      },
      "source": [
        "**Sistetizar la información**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5hyY6nmtcU"
      },
      "source": [
        "dataset.loc[dataset.paralelo == \"A1\", 'paralelo'] = \"A\"\n",
        "dataset.loc[dataset.paralelo == \"A2\", 'paralelo'] = \"A\"\n",
        "dataset.loc[dataset.paralelo == \"A3\", 'paralelo'] = \"A\"\n",
        "dataset.loc[dataset.paralelo == \"A4\", 'paralelo'] = \"A\"\n",
        "dataset.loc[dataset.paralelo != \"A\", 'paralelo'] = \"O\"\n",
        "\n",
        "dataset.loc[dataset.estado_matricula == \"REUBICADA\", 'estado_matricula'] = \"REPROBADA\"\n",
        "dataset.loc[dataset.etnia != \"MESTIZO\", 'etnia'] = \"OTRO\"\n",
        "\n",
        "dataset.loc[dataset.estado_civil == \"SOLTERO(A)\", 'estado_civil'] = \"SOLTERO\"\n",
        "dataset.loc[dataset.estado_civil != \"SOLTERO\", 'estado_civil'] = \"OTRO\"\n",
        "dataset.loc[dataset.canton_nacimiento != \"LOJA\", 'canton_nacimiento'] = \"OTRO\"\n",
        "\n",
        "dataset.loc[dataset.numero_hijos == 0, 'numero_hijos'] = \"NO\"\n",
        "dataset.loc[dataset.numero_hijos != \"NO\", 'numero_hijos'] = \"SI\"\n",
        "dataset.loc[dataset.ingreso_estudiante == 0, 'ingreso_estudiante'] = \"NO\"\n",
        "dataset.loc[dataset.ingreso_estudiante != \"NO\", 'ingreso_estudiante'] = \"SI\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hh1Xh-K9oTv"
      },
      "source": [
        "**Codificar las etiquetas de destino (Código de categoría)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZaC6rtuknZA"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "dataset['estado_matricula'] = label_encoder.fit_transform(dataset['estado_matricula'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJzuymR0nzF"
      },
      "source": [
        "**Convertir las variables categóricas en variables ficticias (indicadoras)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1dCJZog0H5p"
      },
      "source": [
        "dummies = pd.get_dummies(dataset['estado_asignatura'])\n",
        "dataset['estado_asignatura'] = dummies.REPROBADA\n",
        "\n",
        "dummies = pd.get_dummies(dataset[\"genero\"])\n",
        "dataset['genero'] = dummies.FEMENINO\n",
        "\n",
        "dummies = pd.get_dummies(dataset['estado_civil'])\n",
        "dataset['estado_civil'] = dummies.OTRO\n",
        "\n",
        "dummies = pd.get_dummies(dataset['etnia'])\n",
        "dataset['etnia'] = dummies.OTRO\n",
        "\n",
        "dummies = pd.get_dummies(dataset['sector_procedencia'])\n",
        "dataset['sector_procedencia'] = dummies.RURAL\n",
        "\n",
        "dummies = pd.get_dummies(dataset['canton_nacimiento'])\n",
        "dataset['canton_nacimiento'] = dummies.OTRO\n",
        "\n",
        "dummies = pd.get_dummies(dataset['trabaja'])\n",
        "dataset['trabaja'] = dummies.SI\n",
        "\n",
        "dummies = pd.get_dummies(dataset['numero_hijos'])\n",
        "dataset['numero_hijos'] = dummies.SI\n",
        "\n",
        "dummies = pd.get_dummies(dataset['ingreso_estudiante'])\n",
        "dataset['ingreso_estudiante'] = dummies.SI\n",
        "\n",
        "dummies = pd.get_dummies(dataset[\"paralelo\"])\n",
        "dataset['paralelo'] = dummies.A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFXyA4Cc-ptT"
      },
      "source": [
        "**Generar el nuevo campo edad y aplicar el formato a asiganturas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C8HaAvj-qnq"
      },
      "source": [
        "dataset['edad'] = dataset.apply(lambda x: cal_edad(x['fecha_nacimiento']), axis=1)\n",
        "dataset['asignatura'] = dataset.apply(lambda x: format(x['asignatura']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MbaJqeb9yHN"
      },
      "source": [
        "**Eliminar nombres redundantes de las asignaturas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4SRSo0a9y7b"
      },
      "source": [
        "dataset.loc[dataset.asignatura == \"ECUACIONES_DIFERENCIAL\", 'asignatura'] = \"ECUACIONES_DIFERENCIALES\"\n",
        "dataset.loc[dataset.asignatura == \"CONTROL_AUTOMATICO_Y_ASISTIDO_POR_COMPUTADORES\", 'asignatura'] = \"CONTROL_AUTOMATIZADO_ASISTIDO_POR_COMPUTADORES\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"FISICA_I\", 'asignatura'] = \"FISICA\"\n",
        "dataset.loc[dataset.asignatura == \"FISICA_1\", 'asignatura'] = \"FISICA\"\n",
        "dataset.loc[dataset.asignatura == \"ESTRUCTURA_DE_DATOS_II\", 'asignatura'] = \"ESTRUCTURA_DE_DATOS\"\n",
        "dataset.loc[dataset.asignatura == \"ESTRUCTURA_DE_DATOS_OO\", 'asignatura'] = \"ESTRUCTURA_DE_DATOS\"\n",
        "dataset.loc[dataset.asignatura == \"INGENIERIA_DEL_SOFTWARE\", 'asignatura'] = \"INGENIERIA_DEL_SOFTWARE_I\"\n",
        "dataset.loc[dataset.asignatura == \"INGENIERIA_DE_SOFTWARE\", 'asignatura'] = \"INGENIERIA_DEL_SOFTWARE_I\"\n",
        "dataset.loc[dataset.asignatura == \"DISENO_Y_GESTION_DE_BASES_DE_DATOS\", 'asignatura'] = \"DISENO_Y_GESTION_DE_BASE_DE_DATOS\"\n",
        "dataset.loc[dataset.asignatura == \"ARQUITECTURA_DE_COMPUTADORES\", 'asignatura'] = \"ARQUITECTURA_DE_COMPUTADORAS\"\n",
        "dataset.loc[dataset.asignatura == \"INTELIGENCIA_ARIFICIAL\", 'asignatura'] = \"INTELIGENCIA_ARTIFICIAL\"\n",
        "dataset.loc[dataset.asignatura == \"DIENO_DIGITAL\", 'asignatura'] = \"DISENO_DIGITAL\"\n",
        "dataset.loc[dataset.asignatura == \"SIMULACIOM\", 'asignatura'] = \"SIMULACION\"\n",
        "dataset.loc[dataset.asignatura == \"FUNDAMENTOS_BASICOS_DE_COMPUTACION\", 'asignatura'] = \"FUNDAMENTOS_BASICOS_DE_LA_COMPUTACION\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"PROYECTOS_INFORMATICOS\", 'asignatura'] = \"PROYECTOS_INFORMATICOS_I\"\n",
        "dataset.loc[dataset.asignatura == \"ANALISI_NUMERICO\", 'asignatura'] = \"ANALISIS_NUMERICO\" \n",
        "dataset.loc[dataset.asignatura == \"SISTEMAS_DE_INFORMACION_I\", 'asignatura'] = \"SISTEMAS_DE_INFORMACION\"\n",
        "dataset.loc[dataset.asignatura == \"SISTEMAS_DE_INFORMACION_II\", 'asignatura'] = \"SISTEMAS_DE_INFORMACION\"\n",
        "dataset.loc[dataset.asignatura == \"SISTEMAS_DE_INFORMACION_2\", 'asignatura'] = \"SISTEMAS_DE_INFORMACION\"\n",
        "dataset.loc[dataset.asignatura == \"SISTEMAS_DE_INFORMACION_1\", 'asignatura'] = \"SISTEMAS_DE_INFORMACION\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"ANTEPROYECTOS_DE_TESIS\", 'asignatura'] = \"PROYECTO_DE_TRABAJO_DE_TITULACION\"\n",
        "dataset.loc[dataset.asignatura == \"ANTEPROYECTOS\", 'asignatura'] = \"PROYECTO_DE_TRABAJO_DE_TITULACION\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"LENGUAJES_FORMALES_Y_TEORIA_DE_AUTOMATAS\", 'asignatura'] = \"AUTOMATAS_Y_LENGUAJES_FORMALES\"\n",
        "dataset.loc[dataset.asignatura == \"LENGUAJES_FORMALES\", 'asignatura'] = \"AUTOMATAS_Y_LENGUAJES_FORMALES\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"MATEMATICAS\", 'asignatura'] = \"CALCULO_DIFERENCIAL\"\n",
        "dataset.loc[dataset.asignatura == \"MATEMATICAS_2\", 'asignatura'] = \"CALCULO_INTEGRAL\"\n",
        "dataset.loc[dataset.asignatura == \"CALCULO_II\", 'asignatura'] = \"CALCULO_INTEGRAL\"\n",
        "\n",
        "dataset.loc[dataset.asignatura == \"FUNDAMENTOS_BASICOS_DE_LA_COMPUTACION\", 'asignatura'] = \"PROGRAMACION_I\"\n",
        "dataset.loc[dataset.asignatura == \"PROGRAMACION_BASICA\", 'asignatura'] = \"PROGRAMACION_I\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7sSZMaSvi98"
      },
      "source": [
        "**Código para identificar las asignaturas semejantes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr7B3xVZedA3",
        "outputId": "4be461dd-477d-4333-a4e4-a3a3c2ec52fd"
      },
      "source": [
        "asignaturas = dataset['asignatura']\n",
        "asignaturas = asignaturas.drop_duplicates().to_list()\n",
        "print(len(asignaturas))\n",
        "for asig in asignaturas:\n",
        "  asig = str(asig)\n",
        "  print (asig , \" ~= \" , str(encontrarAsignaturaSemejante(asignaturas, asig)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n",
            "ELECTRICIDAD  ~=  []\n",
            "ALGEBRA_LINEAL  ~=  []\n",
            "COMUNICACION_PROFESIONAL  ~=  []\n",
            "INTRODUCCION_A_LAS_CIENCIAS_DE_LA_COMPUTACION  ~=  []\n",
            "TEORIA_DE_LA_PROGRAMACION  ~=  []\n",
            "MATEMATICAS_DISCRETAS  ~=  []\n",
            "PROGRAMACION_ORIENTADA_A_OBJETOS  ~=  []\n",
            "DISENO_DE_CIRCUITOS  ~=  []\n",
            "TECNOLOGIA_Y_CAMBIO_SOCIAL  ~=  []\n",
            "CALCULO_DIFERENCIAL  ~=  []\n",
            "TEORIA_DE_LA_DISTRIBUCION_Y_PROBABILIDAD  ~=  []\n",
            "ECUACIONES_DIFERENCIALES  ~=  []\n",
            "CATEDRA_INTEGRADORA:_PROYECTO_DE_VINCULACION:_\"CENTRO_DE_ASESORIA_TECNOLOGICA\"  ~=  []\n",
            "ESTRUCTURAS_DE_DATOS_AVANZADAS  ~=  []\n",
            "ESTADISTICA_ANALITICA  ~=  []\n",
            "ARQUITECTURA_DE_ORDENADORES  ~=  []\n",
            "CALCULO_INTEGRAL  ~=  []\n",
            "BANCOS_DE_DATOS  ~=  []\n",
            "ESTRUCTURAS_DE_DATOS_Y_ALGORITMOS_FUNDAMENTALES  ~=  []\n",
            "INGENIERIA_DE_LA_CONTAMINACION  ~=  []\n",
            "PROCESOS_DE_SOFTWARE  ~=  []\n",
            "PROCESAMIENTO_DE_TRANSACCIONES  ~=  []\n",
            "QUIMICA  ~=  []\n",
            "EXPRESION_ORAL_Y_ESCRITA  ~=  []\n",
            "FISICA  ~=  []\n",
            "FUNDAMENTOS_INFORMATICOS  ~=  []\n",
            "LABORATORIO_DE_FISICA_I  ~=  ['LABORATORIO_DE_FISICA_II']\n",
            "CALCULO_I  ~=  []\n",
            "PROGRAMACION_I  ~=  ['PROGRAMACION_II']\n",
            "PROBABILIDAD_E_INFERENCIA_ESTADISTICA  ~=  []\n",
            "ECOLOGIA_Y_MEDIO_AMBIENTE_TECNOLOGICO  ~=  []\n",
            "ESTRUCTURA_DE_DATOS  ~=  []\n",
            "FISICA_II  ~=  []\n",
            "ELECTRONICA_DIGITAL  ~=  []\n",
            "PROGRAMACION_II  ~=  ['PROGRAMACION_I']\n",
            "BASE_DE_DATOS_I  ~=  []\n",
            "INGENIERIA_DEL_SOFTWARE_I  ~=  ['INGENIERIA_DE_SOFTWARE_II']\n",
            "METODOLOGIA_DE_LA_INVESTIGACION  ~=  []\n",
            "DISENO_Y_GESTION_DE_BASE_DE_DATOS  ~=  []\n",
            "METODOLOGIA_DE_LA_PROGRAMACION  ~=  []\n",
            "ECONOMIA  ~=  []\n",
            "CONTABILIDAD_GENERAL  ~=  []\n",
            "ARQUITECTURA_DE_COMPUTADORAS  ~=  []\n",
            "CONTABILIDAD_DE_COSTOS  ~=  []\n",
            "ESTADISTICA_INFERENCIAL  ~=  []\n",
            "ETICA_PROFESIONAL  ~=  []\n",
            "ADMINISTRACION_DE_EMPRESAS  ~=  []\n",
            "ANALISIS_Y_DISENO_DE_SISTEMAS  ~=  []\n",
            "LENGUAJE_ENSAMBLADOR  ~=  []\n",
            "PROGRAMACION_AVANZADA  ~=  []\n",
            "DISENO_DIGITAL  ~=  []\n",
            "PROYECTOS_INFORMATICOS_I  ~=  ['PROYECTOS_INFORMATICOS_II']\n",
            "DERECHO_INFORMATICO  ~=  []\n",
            "DISENO_DE_SISTEMAS  ~=  []\n",
            "SIMULACION  ~=  []\n",
            "TEORIA_DE_TELECOMUNICACIONES  ~=  []\n",
            "SISTEMAS_OPERATIVOS  ~=  []\n",
            "GESTION_DE_REDES  ~=  []\n",
            "AUDITORIA_INFORMATICA  ~=  []\n",
            "PROYECTOS_INFORMATICOS_II  ~=  ['PROYECTOS_INFORMATICOS_I']\n",
            "ANALISIS_NUMERICO  ~=  []\n",
            "INVESTIGACION_DE_OPERACIONES  ~=  []\n",
            "ADMINISTRACION_DE_CENTROS_DE_COMPUTO  ~=  []\n",
            "SISTEMAS_DE_INFORMACION  ~=  []\n",
            "PROYECTO_DE_TRABAJO_DE_TITULACION  ~=  []\n",
            "AUTOMATAS_Y_LENGUAJES_FORMALES  ~=  []\n",
            "INGENIERIA_DE_SOFTWARE_II  ~=  ['INGENIERIA_DEL_SOFTWARE_I']\n",
            "MODELAMIENTO_MATEMATICO  ~=  []\n",
            "INTELIGENCIA_ARTIFICIAL  ~=  []\n",
            "COMPILADORES  ~=  []\n",
            "TRABAJO_DE_TITULACION  ~=  []\n",
            "CONTROL_AUTOMATIZADO_ASISTIDO_POR_COMPUTADORES  ~=  []\n",
            "SISTEMAS_EXPERTOS  ~=  []\n",
            "PROCESO_INVESTIGATIVO  ~=  []\n",
            "GEOMETRIA_ANALITICA  ~=  []\n",
            "CONTROL_AUTOMATICO  ~=  []\n",
            "ESTADISTICA  ~=  []\n",
            "GEOMETRIA_PLANA  ~=  []\n",
            "INVESTIGACION  ~=  []\n",
            "ESTRUCTURA_DE_DATOS_ORIENTADA_A_OBJETOS  ~=  []\n",
            "ELECTRONICA_BASICA  ~=  []\n",
            "LABORATORIO_DE_FISICA_II  ~=  ['LABORATORIO_DE_FISICA_I']\n",
            "PROGRAMACIONES_.NET  ~=  []\n",
            "APLICACIONES_WEB  ~=  []\n",
            "APLICACIONES_MYSQL_Y_UML  ~=  []\n",
            "ADMINISTRACIONDE_BASES_DE_DATOS_SQL_SERVER  ~=  []\n",
            "METODOLOGIA_DE_LA_PROGRAMACION_Y_ALGORITMOS  ~=  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgaMSV6rvbRz"
      },
      "source": [
        "**Código para identificar los números de cédula que no cumplen con el algoritmo de verificar cédulas ecuatorianas**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYSMZDAderc1",
        "outputId": "24154c4b-5d35-45de-d805-56b2f6b159e6"
      },
      "source": [
        "allCedulas = dataset['cedula']\n",
        "cedulas = allCedulas.drop_duplicates().to_list()\n",
        "print(\"Total de cédulas únicas: \", len(cedulas))\n",
        "lista = list()\n",
        "for cedula in cedulas:\n",
        "  cedula = str(cedula)\n",
        "  if(len(cedula) == 10): \n",
        "    if(validarCedulaEcuador(cedula)==False):\n",
        "      lista.append(cedula)\n",
        "  else:\n",
        "    lista.append(cedula)\n",
        "\n",
        "print(\"Las cédulas no validadas son:\", len(lista))\n",
        "print(lista)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de cédulas únicas:  1270\n",
            "Las cédulas no validadas son: 2\n",
            "['77343664', 'FB491880']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTgH9mWiwEcb"
      },
      "source": [
        "**Calculamos la cantidad de registros que tiene cada número de cédula (Cédulas no validadas)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBIKUq_uv-n9",
        "outputId": "ba518b60-7514-42f3-fe9c-647beea3d23d"
      },
      "source": [
        "def countRowById(dataset, ced):\n",
        "  filtro = dataset[dataset['cedula'].str.contains(ced, case=False)]['cedula']\n",
        "  return filtro\n",
        "\n",
        "for ced in lista:\n",
        "  print(ced, '\\t\\t',countRowById(dataset, ced).count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77343664 \t\t 5\n",
            "FB491880 \t\t 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mhKADZVD_HD",
        "outputId": "6242a797-7f2e-42a9-c291-85ecac9199f5"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30187, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6XESPv2HI5A"
      },
      "source": [
        "**Generar dataset´s**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exjuTAIHIJDE"
      },
      "source": [
        "dataset_sistemas = dataset[dataset['carrera'] == \"INGENIERIA EN SISTEMAS\"]\n",
        "dataset_computacion = dataset[dataset['carrera'] == \"COMPUTACION\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLwK8rPuwOO8"
      },
      "source": [
        "columns = ['carrera', 'periodo_lectivo', 'nivel', 'fecha_nacimiento', 'oferta_academica', 'malla_curricular', 'trabaja'] \n",
        "dataset_sistemas = dataset_sistemas.drop(columns, axis=1)\n",
        "dataset_computacion = dataset_computacion.drop(columns, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLjC-sMNJ40r",
        "outputId": "af485e57-4953-4df5-e153-edb0de89097d"
      },
      "source": [
        "print(len(pd.value_counts(dataset['asignatura'])))\n",
        "print(len(pd.value_counts(dataset_sistemas['asignatura'])))\n",
        "print(len(pd.value_counts(dataset_computacion['asignatura'])))\n",
        "print(\"\")\n",
        "print(len(pd.value_counts(dataset['cedula'])))\n",
        "print(len(pd.value_counts(dataset_sistemas['cedula'])))\n",
        "print(len(pd.value_counts(dataset_computacion['cedula'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n",
            "71\n",
            "22\n",
            "\n",
            "1270\n",
            "1038\n",
            "252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LDk0zhBOtZh"
      },
      "source": [
        "**DATASETS POR CICLO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PXVwdJyjRq"
      },
      "source": [
        "dc4 = dataset_computacion[dataset_computacion['ciclo'] == 4]\n",
        "dc3 = dataset_computacion[dataset_computacion['ciclo'] == 3]\n",
        "dc2 = dataset_computacion[dataset_computacion['ciclo'] == 2]\n",
        "dc1 = dataset_computacion[dataset_computacion['ciclo'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFraJURPunz"
      },
      "source": [
        "ds10 = dataset_sistemas[dataset_sistemas['ciclo'] == 10]\n",
        "ds9 = dataset_sistemas[dataset_sistemas['ciclo'] == 9]\n",
        "ds8 = dataset_sistemas[dataset_sistemas['ciclo'] == 8]\n",
        "ds7 = dataset_sistemas[dataset_sistemas['ciclo'] == 7]\n",
        "ds6 = dataset_sistemas[dataset_sistemas['ciclo'] == 6]\n",
        "ds5 = dataset_sistemas[dataset_sistemas['ciclo'] == 5]\n",
        "ds4 = dataset_sistemas[dataset_sistemas['ciclo'] == 4]\n",
        "ds3 = dataset_sistemas[dataset_sistemas['ciclo'] == 3]\n",
        "ds2 = dataset_sistemas[dataset_sistemas['ciclo'] == 2]\n",
        "ds1 = dataset_sistemas[dataset_sistemas['ciclo'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXnnhAvQom5",
        "outputId": "099e304d-09e4-4fe7-9e55-a2f4e7758548"
      },
      "source": [
        "cedulas_s10 = pd.merge(ds1, ds10, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s10.count())\n",
        "cedulas_s9 = pd.merge(ds1, ds9, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s9.count())\n",
        "cedulas_s8 = pd.merge(ds1, ds8, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s8.count())\n",
        "cedulas_s7 = pd.merge(ds1, ds7, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s7.count())\n",
        "cedulas_s6 = pd.merge(ds1, ds6, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s6.count())\n",
        "cedulas_s5 = pd.merge(ds1, ds5, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s5.count())\n",
        "cedulas_s4 = pd.merge(ds1, ds4, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s4.count())\n",
        "cedulas_s3 = pd.merge(ds1, ds3, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s3.count())\n",
        "cedulas_s2 = pd.merge(ds1, ds2, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_s2.count())\n",
        "cedulas_s1 = ds1['cedula'].drop_duplicates()\n",
        "print(cedulas_s1.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165\n",
            "184\n",
            "198\n",
            "221\n",
            "258\n",
            "325\n",
            "359\n",
            "387\n",
            "458\n",
            "571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xRPSZAb3w7X"
      },
      "source": [
        "ds10 = ds10[ds10['cedula'].isin(cedulas_s10)]\n",
        "ds9 = ds9[ds9['cedula'].isin(cedulas_s9)]\n",
        "ds8 = ds8[ds8['cedula'].isin(cedulas_s8)]\n",
        "ds7 = ds7[ds7['cedula'].isin(cedulas_s7)]\n",
        "ds6 = ds6[ds6['cedula'].isin(cedulas_s6)]\n",
        "ds5 = ds5[ds5['cedula'].isin(cedulas_s5)]\n",
        "ds4 = ds4[ds4['cedula'].isin(cedulas_s4)]\n",
        "ds3 = ds3[ds3['cedula'].isin(cedulas_s3)]\n",
        "ds2 = ds2[ds2['cedula'].isin(cedulas_s2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJZRcVHAfx5s",
        "outputId": "bb6d9dd9-d4b4-4af6-e04d-4678c7e35b93"
      },
      "source": [
        "cedulas_c4 = pd.merge(dc1, dc4, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_c4.count())\n",
        "cedulas_c3 = pd.merge(dc1, dc3, on='cedula')['cedula'].drop_duplicates()\n",
        "print(cedulas_c3.count())\n",
        "cedulas_c2 = pd.merge(dc1, dc2, on='cedula')['cedula'].drop_duplicates() \n",
        "print(cedulas_c2.count())\n",
        "cedulas_c1 = dc1['cedula'].drop_duplicates() \n",
        "print(cedulas_c1.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "20\n",
            "77\n",
            "232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb7qgy_5loJa"
      },
      "source": [
        "dc4 = dc4[dc4['cedula'].isin(cedulas_c4)]\n",
        "dc3 = dc3[dc3['cedula'].isin(cedulas_c3)]\n",
        "dc2 = dc2[dc2['cedula'].isin(cedulas_c2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YFo8gtz_C4l",
        "outputId": "0911e3db-deaf-4c00-8ea4-56b6ce6a73e1"
      },
      "source": [
        "columnas = ds2.columns.to_list()\n",
        "columnas.remove('asignatura')\n",
        "columnas.remove('estado_asignatura')\n",
        "columnas = ds2['asignatura'].drop_duplicates().to_list() + columnas\n",
        "dt_tmp = pd.DataFrame(columns=columnas)\n",
        "dt_tmp.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifQItpXyrfnQ",
        "outputId": "0d150379-4515-48f7-93a4-5f779b2dc403"
      },
      "source": [
        "dic = {}\n",
        "ds =  pd.concat([ds1, ds2, ds3], axis=0)\n",
        "for ced in cedulas_s3:\n",
        "  aux = ds[ds.cedula==ced]\n",
        "  dic = {}\n",
        "  for index, row in aux.iterrows():\n",
        "    if row['asignatura'] not in dic:\n",
        "      if isColumn(columnas, row['asignatura']):\n",
        "        dic[row['asignatura']] = row['estado_asignatura']\n",
        "    for column_name, value in row.iteritems():\n",
        "      dic[column_name] = value\n",
        "  del dic['asignatura']\n",
        "  del dic['estado_asignatura']\n",
        "  dt_tmp = dt_tmp.append(dic, ignore_index=True)\n",
        "\n",
        "print(dt_tmp.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(387, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xepPY38wqXyC",
        "outputId": "c097de3f-cc0f-496f-9742-0dbcac993adb"
      },
      "source": [
        "dt_tmp.isnull().sum() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PROGRAMACION_I                             5\n",
              "CALCULO_INTEGRAL                          64\n",
              "PROBABILIDAD_E_INFERENCIA_ESTADISTICA    128\n",
              "ECOLOGIA_Y_MEDIO_AMBIENTE_TECNOLOGICO    130\n",
              "ALGEBRA_LINEAL                             1\n",
              "ESTRUCTURA_DE_DATOS                      124\n",
              "FISICA_II                                 64\n",
              "GEOMETRIA_ANALITICA                      259\n",
              "CALCULO_DIFERENCIAL                       10\n",
              "PROCESO_INVESTIGATIVO                    238\n",
              "FISICA                                     0\n",
              "LABORATORIO_DE_FISICA_II                 376\n",
              "QUIMICA                                   10\n",
              "EXPRESION_ORAL_Y_ESCRITA                 143\n",
              "FUNDAMENTOS_INFORMATICOS                 144\n",
              "cedula                                     0\n",
              "genero                                     0\n",
              "estado_civil                               0\n",
              "etnia                                      0\n",
              "sector_procedencia                         0\n",
              "canton_nacimiento                          0\n",
              "ingreso_estudiante                         0\n",
              "numero_hijos                               0\n",
              "ciclo                                      0\n",
              "estado_matricula                           0\n",
              "paralelo                                   0\n",
              "edad                                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEWLegP1QVAT"
      },
      "source": [
        "dt_tmp = dt_tmp.fillna(method='bfill', limit = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsxft5JZe3aq"
      },
      "source": [
        "orden_col = ['cedula', 'ALGEBRA_LINEAL', 'CALCULO_DIFERENCIAL', 'CALCULO_INTEGRAL', 'ECOLOGIA_Y_MEDIO_AMBIENTE_TECNOLOGICO', 'ESTRUCTURA_DE_DATOS', 'EXPRESION_ORAL_Y_ESCRITA', 'FISICA', 'FISICA_II', 'FUNDAMENTOS_INFORMATICOS', 'PROBABILIDAD_E_INFERENCIA_ESTADISTICA', 'PROGRAMACION_I', 'QUIMICA', 'canton_nacimiento', 'ciclo', 'edad', 'estado_civil', 'etnia', 'genero', 'ingreso_estudiante', 'numero_hijos', 'paralelo', 'sector_procedencia', 'estado_matricula']\n",
        "dt_tmp = dt_tmp[orden_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHpgOdqFBPEX"
      },
      "source": [
        "**Selección de caracteristicas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8ftjrgOBVe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfd0fa5-79f4-4d6d-c31b-f388e6073083"
      },
      "source": [
        "features_del = ['cedula', 'ciclo', 'edad', 'estado_civil', 'etnia', 'genero', 'ingreso_estudiante', 'numero_hijos', 'paralelo', 'sector_procedencia']\n",
        "ONG_data = dt_tmp.drop(features_del, axis=1)\n",
        "print(ONG_data.shape)\n",
        "ONG_data.columns\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "#Aplicando el algoritmo univariante de prueba F. \n",
        "target = ONG_data['estado_matricula']\n",
        "k = 5 # número de atributos a seleccionar\n",
        "entrenar = ONG_data.drop(['estado_matricula'], axis=1)\n",
        "columnas = list(entrenar.columns.values)\n",
        "seleccionadas = SelectKBest(f_classif, k = k).fit(entrenar, target)\n",
        "atrib = seleccionadas.get_support()\n",
        "atributos = [columnas[i] for i in list(atrib.nonzero()[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(387, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd4rxe3oBV4t"
      },
      "source": [
        "**DIVISIÓN DE LOS DATOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyTF2MFWUozM",
        "outputId": "a58d4074-5cdf-4f96-f361-ef5d887793ec"
      },
      "source": [
        "make_classification\n",
        "\n",
        "features = atributos ###['ALGEBRA_LINEAL', 'CALCULO_DIFERENCIAL',  'FISICA', 'FISICA_II', 'PROGRAMACION_I']\n",
        "\n",
        "X =  dt_tmp[features].values\n",
        "\n",
        "y = dt_tmp['estado_matricula'].values\n",
        "print(pd.value_counts(y))\n",
        "print(y.shape)\n",
        "os =  RandomOverSampler(sampling_strategy = 0.45, random_state = 50)\n",
        "\n",
        "X, y = os.fit_sample(X, y)\n",
        "\n",
        "print(pd.value_counts(y))\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    289\n",
            "1     98\n",
            "dtype: int64\n",
            "(387,)\n",
            "0    289\n",
            "1    130\n",
            "dtype: int64\n",
            "(419,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyLzHSkDgYEp"
      },
      "source": [
        "**Entrenamiento de los modelos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFTnEAbdk57s",
        "outputId": "7c11ebe3-6d9d-4476-b752-152c194f1cd8"
      },
      "source": [
        "from sklearn import linear_model\n",
        "linear_model = linear_model.LogisticRegression() \n",
        "linear_model.fit(X_train, y_train.ravel())\n",
        "predict = linear_model.predict(X_validation)\n",
        "print(\"LogisticRegression()\")\n",
        "print(linear_model.score(X_test, y_test))\n",
        "print(metrics.confusion_matrix(y_validation, predict))\n",
        "print(\"Accuracy = {0:.3f}\".format(metrics.accuracy_score(y_validation, predict)))\n",
        "print(\"Precision = {0:.3f}\".format(metrics.precision_score(y_validation, predict)))\n",
        "print(\"Recall = {0:.3f}\".format(metrics.recall_score(y_validation, predict)))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFC_model = RandomForestClassifier()\n",
        "RFC_model.fit(X_train, y_train.ravel())\n",
        "predict = RFC_model.predict(X_validation)\n",
        "print(\"\\nRandomForestClassifier\")\n",
        "print(RFC_model.score(X_test, y_test))\n",
        "print(metrics.confusion_matrix(y_validation, predict))\n",
        "print(\"Accuracy RF = {0:.3f}\".format(metrics.accuracy_score(y_validation, predict)))\n",
        "print(\"Precision RF = {0:.3f}\".format(metrics.precision_score(y_validation, predict)))\n",
        "print(\"Recall RF = {0:.3f}\".format(metrics.recall_score(y_validation, predict)))\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier()\n",
        "clf.fit(X_train, y_train.ravel())\n",
        "predict = clf.predict(X_validation)\n",
        "print(\"\\nMLPClassifier\")\n",
        "print(clf.score(X_test, y_test))\n",
        "print(metrics.confusion_matrix(y_validation, predict))\n",
        "print(\"Accuracy = {0:.3f}\".format(metrics.accuracy_score(y_validation, predict)))\n",
        "print(\"Precision = {0:.3f}\".format(metrics.precision_score(y_validation, predict)))\n",
        "print(\"Recall = {0:.3f}\".format(metrics.recall_score(y_validation, predict)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression()\n",
            "0.8059701492537313\n",
            "[[55  3]\n",
            " [10 16]]\n",
            "Accuracy = 0.845\n",
            "Precision = 0.842\n",
            "Recall = 0.615\n",
            "\n",
            "RandomForestClassifier\n",
            "0.7910447761194029\n",
            "[[57  1]\n",
            " [11 15]]\n",
            "Accuracy RF = 0.857\n",
            "Precision RF = 0.938\n",
            "Recall RF = 0.577\n",
            "\n",
            "MLPClassifier\n",
            "0.8059701492537313\n",
            "[[57  1]\n",
            " [11 15]]\n",
            "Accuracy = 0.857\n",
            "Precision = 0.938\n",
            "Recall = 0.577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN0BiAmZga9W"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cH7z7JNgVAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c478f7e8-543b-4055-a34c-ebf4487de600"
      },
      "source": [
        "predict = linear_model.predict(X_test)\n",
        "print(\"LogisticRegression()\")\n",
        "print(metrics.confusion_matrix(y_test, predict))\n",
        "print(\"Accuracy = {0:.3f}\".format(metrics.accuracy_score(y_test, predict)))\n",
        "print(\"Precision = {0:.3f}\".format(metrics.precision_score(y_test, predict)))\n",
        "print(\"Recall = {0:.3f}\".format(metrics.recall_score(y_test, predict)))\n",
        "\n",
        "predict = RFC_model.predict(X_test)\n",
        "print(\"\\nRandomForestClassifier\")\n",
        "print(metrics.confusion_matrix(y_test, predict))\n",
        "print(\"Accuracy RF = {0:.3f}\".format(metrics.accuracy_score(y_test, predict)))\n",
        "print(\"Precision RF = {0:.3f}\".format(metrics.precision_score(y_test, predict)))\n",
        "print(\"Recall RF = {0:.3f}\".format(metrics.recall_score(y_test, predict)))\n",
        "\n",
        "predict = clf.predict(X_test)\n",
        "print(\"\\nMLPClassifier\")\n",
        "print(metrics.confusion_matrix(y_test, predict))\n",
        "print(\"Accuracy = {0:.3f}\".format(metrics.accuracy_score(y_test, predict)))\n",
        "print(\"Precision = {0:.3f}\".format(metrics.precision_score(y_test, predict)))\n",
        "print(\"Recall = {0:.3f}\".format(metrics.recall_score(y_test, predict)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression()\n",
            "[[41  2]\n",
            " [11 13]]\n",
            "Accuracy = 0.806\n",
            "Precision = 0.867\n",
            "Recall = 0.542\n",
            "\n",
            "RandomForestClassifier\n",
            "[[40  3]\n",
            " [11 13]]\n",
            "Accuracy RF = 0.791\n",
            "Precision RF = 0.812\n",
            "Recall RF = 0.542\n",
            "\n",
            "MLPClassifier\n",
            "[[41  2]\n",
            " [12 12]]\n",
            "Accuracy = 0.791\n",
            "Precision = 0.857\n",
            "Recall = 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOCzJGNTyc6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5f9b7f99-4517-4cb9-8980-f461ddf4e6ac"
      },
      "source": [
        "from sklearn.externals import joblib \n",
        "joblib.dump(clf, 'modelo_entrenado.pkl')\n",
        "#clf_load = joblib.load('modelo_entrenado.pkl')\n",
        "\n",
        "from google.colab import files\n",
        "#dt_tmp.to_csv('dataset10.csv') \n",
        "files.download('modelo_entrenado.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9319df70-6079-40ed-b8f2-bdb7702e166d\", \"modelo_entrenado.pkl\", 32544)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}